{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance with 75% training size\n",
      "Mean Squared Error:  0.0\n",
      "Confusion Matrix:  [[15  0  0]\n",
      " [ 0 11  0]\n",
      " [ 0  0 12]]\n",
      "Precision:  [1.0, 1.0, 1.0]\n",
      "Recall:  [1.0, 1.0, 1.0]\n",
      "F_measure:  [1.0, 1.0, 1.0]\n",
      "Accuracy:  1.0\n",
      "******\n",
      "Performance with 10 fold\n",
      "Mean Squared Error:  0.0148148148148\n",
      "Confusion Matrix:  [[35  0  0]\n",
      " [ 0 49  1]\n",
      " [ 0  1 49]]\n",
      "Precision:  [1.0, 0.98, 0.98]\n",
      "Recall:  [1.0, 0.98, 0.98]\n",
      "F_measure:  [1.0, 0.98, 0.98]\n",
      "Accuracy:  0.985185185185\n",
      "Mean Squared Error:  0.0148148148148\n",
      "Confusion Matrix:  [[35  0  0]\n",
      " [ 0 49  1]\n",
      " [ 0  1 49]]\n",
      "Precision:  [1.0, 0.98, 0.98]\n",
      "Recall:  [1.0, 0.98, 0.98]\n",
      "F_measure:  [1.0, 0.98, 0.98]\n",
      "Accuracy:  0.985185185185\n",
      "Mean Squared Error:  0.0148148148148\n",
      "Confusion Matrix:  [[35  0  0]\n",
      " [ 0 49  1]\n",
      " [ 0  1 49]]\n",
      "Precision:  [1.0, 0.98, 0.98]\n",
      "Recall:  [1.0, 0.98, 0.98]\n",
      "F_measure:  [1.0, 0.98, 0.98]\n",
      "Accuracy:  0.985185185185\n",
      "Mean Squared Error:  0.0148148148148\n",
      "Confusion Matrix:  [[45  0  0]\n",
      " [ 0 39  1]\n",
      " [ 0  1 49]]\n",
      "Precision:  [1.0, 0.975, 0.98]\n",
      "Recall:  [1.0, 0.975, 0.98]\n",
      "F_measure:  [1.0, 0.975, 0.98]\n",
      "Accuracy:  0.985185185185\n",
      "Mean Squared Error:  0.0148148148148\n",
      "Confusion Matrix:  [[50  0  0]\n",
      " [ 0 34  1]\n",
      " [ 0  1 49]]\n",
      "Precision:  [1.0, 0.9714285714285714, 0.98]\n",
      "Recall:  [1.0, 0.9714285714285714, 0.98]\n",
      "F_measure:  [1.0, 0.9714285714285714, 0.98]\n",
      "Accuracy:  0.985185185185\n",
      "Mean Squared Error:  0.0148148148148\n",
      "Confusion Matrix:  [[50  0  0]\n",
      " [ 0 34  1]\n",
      " [ 0  1 49]]\n",
      "Precision:  [1.0, 0.9714285714285714, 0.98]\n",
      "Recall:  [1.0, 0.9714285714285714, 0.98]\n",
      "F_measure:  [1.0, 0.9714285714285714, 0.98]\n",
      "Accuracy:  0.985185185185\n",
      "Mean Squared Error:  0.0148148148148\n",
      "Confusion Matrix:  [[50  0  0]\n",
      " [ 0 39  1]\n",
      " [ 0  1 44]]\n",
      "Precision:  [1.0, 0.975, 0.9777777777777777]\n",
      "Recall:  [1.0, 0.975, 0.9777777777777777]\n",
      "F_measure:  [1.0, 0.975, 0.9777777777777777]\n",
      "Accuracy:  0.985185185185\n",
      "Mean Squared Error:  0.0148148148148\n",
      "Confusion Matrix:  [[50  0  0]\n",
      " [ 0 49  1]\n",
      " [ 0  1 34]]\n",
      "Precision:  [1.0, 0.98, 0.9714285714285714]\n",
      "Recall:  [1.0, 0.98, 0.9714285714285714]\n",
      "F_measure:  [1.0, 0.98, 0.9714285714285714]\n",
      "Accuracy:  0.985185185185\n",
      "Mean Squared Error:  0.00740740740741\n",
      "Confusion Matrix:  [[50  0  0]\n",
      " [ 0 49  0]\n",
      " [ 0  1 35]]\n",
      "Precision:  [1.0, 1.0, 0.9722222222222222]\n",
      "Recall:  [1.0, 0.98, 1.0]\n",
      "F_measure:  [1.0, 0.98989898989899, 0.9859154929577464]\n",
      "Accuracy:  0.992592592593\n",
      "Mean Squared Error:  0.0148148148148\n",
      "Confusion Matrix:  [[50  0  0]\n",
      " [ 0 49  1]\n",
      " [ 0  1 34]]\n",
      "Precision:  [1.0, 0.98, 0.9714285714285714]\n",
      "Recall:  [1.0, 0.98, 0.9714285714285714]\n",
      "F_measure:  [1.0, 0.98, 0.9714285714285714]\n",
      "Accuracy:  0.985185185185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nivedita.kalele\\Anaconda2\\lib\\site-packages\\sklearn\\discriminant_analysis.py:453: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math as m\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import sklearn\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "def calculate_mean_variance(X_train,Y_train):\n",
    "    ind= range(len(Y_train))\n",
    "    d={\"x1\":pd.Series(X_train[:,0], index=ind),\"x2\":pd.Series(X_train[:,1], index=ind), \\\n",
    "       \"x3\":pd.Series(X_train[:,2], index=ind),\"x4\":pd.Series(X_train[:,3], index=ind),\"Label\":pd.Series(Y_train)}\n",
    "    df = pd.DataFrame(d)\n",
    "    sf=pd.DataFrame(columns=('x1', 'x2', 'x3','x4'))\n",
    "    vf=pd.DataFrame(columns=('x1', 'x2', 'x3','x4'))\n",
    "    vgf=pd.DataFrame(columns=('x1', 'x2', 'x3','x4'))\n",
    "    for i in range(len(Y_train)):\n",
    "        if(df.Label[i] == 1):\n",
    "            sf.loc[i]=[df.x1[i],df.x2[i],df.x3[i],df.x4[i]]\n",
    "        elif(df.Label[i]==2):\n",
    "            vf.loc[i]=[df.x1[i],df.x2[i],df.x3[i],df.x4[i]]\n",
    "        else:\n",
    "            vgf.loc[i]=[df.x1[i],df.x2[i],df.x3[i],df.x4[i]]\n",
    "    prior_setosa= float(len(sf))/float(len(df))\n",
    "    prior_versi=float(len(vf))/float(len(df))\n",
    "    prior_vergi=float(len(vgf))/float(len(df))\n",
    "    cov_setosa=np.cov(sf.transpose())\n",
    "    cov_versi=np.cov(vf.transpose())\n",
    "    cov_vergi=np.cov(vgf.transpose())\n",
    "    mean_setosa=[np.mean(sf.x1),np.mean(sf.x2),np.mean(sf.x3),np.mean(sf.x4)]\n",
    "    mean_versi=[np.mean(vf.x1),np.mean(vf.x2),np.mean(vf.x3),np.mean(vf.x4)]\n",
    "    mean_vergi=[np.mean(vgf.x1),np.mean(vgf.x2),np.mean(vgf.x3),np.mean(vgf.x4)]\n",
    "#     print prior_setosa, prior_versi, prior_vergi, len(sf), len(df)\n",
    "    return mean_setosa,mean_versi,mean_vergi,cov_setosa,cov_versi,cov_vergi,prior_setosa,prior_versi,prior_vergi\n",
    "\n",
    "def member(mean_setosa,mean_versi,mean_vergi,cov_setosa,cov_versi,cov_vergi,prior_setosa,prior_versi,prior_vergi,X_train):\n",
    "    g1=[]\n",
    "    g2=[]\n",
    "    g3=[]\n",
    "    d=pd.DataFrame(columns=('g1', 'g2','g3'))\n",
    "    for i in range(len(X_train)):\n",
    "        g1x= -m.log(np.linalg.det(cov_setosa)) - (0.5 *(np.dot((X_train[i]-mean_setosa).transpose(),np.dot(np.linalg.inv(cov_setosa),\\\n",
    "                                                      (X_train[i]-mean_setosa))))) + m.log(prior_setosa)\n",
    "        g1.append(g1x)\n",
    "        g2x= -m.log(np.linalg.det(cov_versi)) - (0.5 *(np.dot((X_train[i]-mean_versi).transpose(),np.dot(np.linalg.inv(cov_versi),\\\n",
    "                                                      (X_train[i]-mean_versi))))) + m.log(prior_versi)\n",
    "        g2.append(g2x)\n",
    "        g3x= -m.log(np.linalg.det(cov_vergi)) - (0.5 *(np.dot((X_train[i]-mean_vergi).transpose(),np.dot(np.linalg.inv(cov_vergi),\\\n",
    "                                                      (X_train[i]-mean_vergi))))) + m.log(prior_vergi)\n",
    "        g3.append(g3x)\n",
    "        \n",
    "        d.loc[i]=[g1[i],g2[i],g3[i]]\n",
    "    return d\n",
    "    \n",
    "def classify(d,Fun1,Y_train):\n",
    "    with_max=pd.DataFrame(columns=('g1', 'g2','g3','PLabel','FunLabel','ALabel'))\n",
    "    for i in range(len(d)):\n",
    "        maxv=(max(d.loc[i]))\n",
    "        if(maxv==d.g1[i]):\n",
    "            cl=1\n",
    "        elif(maxv==d.g2[i]):\n",
    "            cl=2\n",
    "        else:\n",
    "            cl=3\n",
    "        with_max.loc[i]=[d.g1[i],d.g2[i],d.g3[i],cl,Fun1[i],Y_train[i]]\n",
    "    return with_max\n",
    "   \n",
    "def confusion_mat(c):\n",
    "#     print c\n",
    "#     A=c.ALabel.value_counts()\n",
    "#     P=c.PLabel.value_counts()\n",
    "    mse=mean_squared_error(c.ALabel, c.PLabel)\n",
    "    print \"Mean Squared Error: \", mse\n",
    "    E11=0\n",
    "    E22=0\n",
    "    E33=0\n",
    "    E12=0\n",
    "    E13=0\n",
    "    E21=0\n",
    "    E23=0\n",
    "    E31=0\n",
    "    E32=0\n",
    "    for i in range(len(c)):\n",
    "        if (c.ALabel[i]== c.PLabel[i] and c.ALabel[i]==1):\n",
    "            E11+=1\n",
    "        if (c.ALabel[i]== c.PLabel[i] and c.ALabel[i]==2):\n",
    "            E22+=1\n",
    "        if (c.ALabel[i]== c.PLabel[i] and c.ALabel[i]==3):\n",
    "            E33+=1\n",
    "        if(c.ALabel[i]==2 and c.PLabel[i]==1):\n",
    "            E12+=1\n",
    "        if(c.ALabel[i]==3 and c.PLabel[i]==1):\n",
    "            E13+=1  \n",
    "        if(c.ALabel[i]==1 and c.PLabel[i]==2):\n",
    "            E21+=1\n",
    "        if(c.ALabel[i]==3 and c.PLabel[i]==2):\n",
    "            E23+=1 \n",
    "        if(c.ALabel[i]==1 and c.PLabel[i]==3):\n",
    "            E31+=1\n",
    "        if(c.ALabel[i]==2 and c.PLabel[i]==3):\n",
    "            E32+=1 \n",
    "#     print count1,count2,count3\n",
    "    con_mat=np.matrix([[E11,E12,E13],[E21, E22, E23],[E31, E32, E33]])\n",
    "    p1=float(E11)/float(E11+E12+E13)\n",
    "    p2=float(E22)/float(E21+E22+E23)\n",
    "    p3=float(E33)/float(E31+E32+E33)\n",
    "    r1=float(E11)/float(E11+E21+E31)\n",
    "    r2=float(E22)/float(E12+E22+E32)\n",
    "    r3=float(E33)/float(E13+E23+E33)\n",
    "    precision=[p1,p2,p3]\n",
    "    recall=[r1,r2,r3]\n",
    "    Accuracy= float(np.trace(con_mat) / float(E11+E12+E13+E21+E22+E23+E31+E32+E33))\n",
    "    f1=2*(float((p1*r1))/float((p1+r1)))\n",
    "    f2=2*(float((p2*r2))/float((p2+r2)))\n",
    "    f3=2*(float((p3*r3))/float((p3+r3)))\n",
    "    print \"Confusion Matrix: \",con_mat\n",
    "    print \"Precision: \",precision\n",
    "    print \"Recall: \" ,recall\n",
    "    print \"F_measure: \",[f1,f2,f3]\n",
    "    print \"Accuracy: \",Accuracy\n",
    "    \n",
    "    \n",
    "def k_fold(X, Y):\n",
    "    kf=sklearn.cross_validation.KFold(n=len(X), n_folds=10, shuffle=False,random_state=None)\n",
    "    for train_index, test_index in kf:\n",
    "        X_train,X_test=X[train_index], X[test_index]\n",
    "        Y_train,Y_test=Y[train_index], Y[test_index]\n",
    "        mean_setosa,mean_versi,mean_vergi,cov_setosa,cov_versi,cov_vergi,prior_setosa,prior_versi,prior_vergi=calculate_mean_variance(X_train,Y_train)\n",
    "        d=member(mean_setosa,mean_versi,mean_vergi,cov_setosa,cov_versi,cov_vergi,prior_setosa,prior_versi,prior_vergi,X_train)\n",
    "        lda = LinearDiscriminantAnalysis()\n",
    "        clf = lda.fit(X_train,Y_train)\n",
    "        Fun1=clf.predict(X_train)\n",
    "        with_max=classify(d,Fun1,Y_train)\n",
    "        confusion_mat(with_max)\n",
    "#     print with_max[0:50]\n",
    "#     print with_max[50:100]\n",
    "#     print with_max[100:149]\n",
    "\n",
    "def main():\n",
    "    iris = load_iris()\n",
    "    X = iris.data \n",
    "    Y = iris.target\n",
    "    enc = LabelEncoder()\n",
    "    label_encoder = enc.fit(Y)\n",
    "    y = label_encoder.transform(Y) + 1\n",
    "#  without fold\n",
    "    print(\"Performance with 75% training size\")\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "    mean_setosa,mean_versi,mean_vergi,cov_setosa,cov_versi,cov_vergi,prior_setosa,prior_versi,prior_vergi=calculate_mean_variance(X_train,y_train)\n",
    "    d=member(mean_setosa,mean_versi,mean_vergi,cov_setosa,cov_versi,cov_vergi,prior_setosa,prior_versi,prior_vergi,X_test)\n",
    "    lda = LinearDiscriminantAnalysis()\n",
    "    clf = lda.fit(X_train,y_train)\n",
    "    Fun1=clf.predict(X_train)\n",
    "    with_max=classify(d,Fun1,y_test)\n",
    "    confusion_mat(with_max)\n",
    "# with fold\n",
    "    print(\"******\")\n",
    "    print(\"Performance with 10 fold\")\n",
    "    k_fold(X,y)\n",
    "    \n",
    "\n",
    "    \n",
    "if __name__ == \"__main__\":main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
