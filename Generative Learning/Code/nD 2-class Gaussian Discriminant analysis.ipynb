{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance with 75% training size\n",
      "0.0\n",
      "Accuracy:  1.0\n",
      "Confusion Matrix:  [[14  0]\n",
      " [ 0 11]]\n",
      "Precision:  [1.0, 1.0]\n",
      "Recall:  [1.0, 1.0]\n",
      "F_measure:  [1.0, 1.0]\n",
      "******\n",
      "Performance with 10 fold\n",
      "0.0\n",
      "Accuracy:  1.0\n",
      "Confusion Matrix:  [[40  0]\n",
      " [ 0 50]]\n",
      "Precision:  [1.0, 1.0]\n",
      "Recall:  [1.0, 1.0]\n",
      "F_measure:  [1.0, 1.0]\n",
      "0.0\n",
      "Accuracy:  1.0\n",
      "Confusion Matrix:  [[40  0]\n",
      " [ 0 50]]\n",
      "Precision:  [1.0, 1.0]\n",
      "Recall:  [1.0, 1.0]\n",
      "F_measure:  [1.0, 1.0]\n",
      "0.0\n",
      "Accuracy:  1.0\n",
      "Confusion Matrix:  [[40  0]\n",
      " [ 0 50]]\n",
      "Precision:  [1.0, 1.0]\n",
      "Recall:  [1.0, 1.0]\n",
      "F_measure:  [1.0, 1.0]\n",
      "0.0\n",
      "Accuracy:  1.0\n",
      "Confusion Matrix:  [[40  0]\n",
      " [ 0 50]]\n",
      "Precision:  [1.0, 1.0]\n",
      "Recall:  [1.0, 1.0]\n",
      "F_measure:  [1.0, 1.0]\n",
      "0.0\n",
      "Accuracy:  1.0\n",
      "Confusion Matrix:  [[40  0]\n",
      " [ 0 50]]\n",
      "Precision:  [1.0, 1.0]\n",
      "Recall:  [1.0, 1.0]\n",
      "F_measure:  [1.0, 1.0]\n",
      "0.0\n",
      "Accuracy:  1.0\n",
      "Confusion Matrix:  [[50  0]\n",
      " [ 0 40]]\n",
      "Precision:  [1.0, 1.0]\n",
      "Recall:  [1.0, 1.0]\n",
      "F_measure:  [1.0, 1.0]\n",
      "0.0\n",
      "Accuracy:  1.0\n",
      "Confusion Matrix:  [[50  0]\n",
      " [ 0 40]]\n",
      "Precision:  [1.0, 1.0]\n",
      "Recall:  [1.0, 1.0]\n",
      "F_measure:  [1.0, 1.0]\n",
      "0.0\n",
      "Accuracy:  1.0\n",
      "Confusion Matrix:  [[50  0]\n",
      " [ 0 40]]\n",
      "Precision:  [1.0, 1.0]\n",
      "Recall:  [1.0, 1.0]\n",
      "F_measure:  [1.0, 1.0]\n",
      "0.0\n",
      "Accuracy:  1.0\n",
      "Confusion Matrix:  [[50  0]\n",
      " [ 0 40]]\n",
      "Precision:  [1.0, 1.0]\n",
      "Recall:  [1.0, 1.0]\n",
      "F_measure:  [1.0, 1.0]\n",
      "0.0\n",
      "Accuracy:  1.0\n",
      "Confusion Matrix:  [[50  0]\n",
      " [ 0 40]]\n",
      "Precision:  [1.0, 1.0]\n",
      "Recall:  [1.0, 1.0]\n",
      "F_measure:  [1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math as m\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import sklearn\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "def calculate_mean_variance(X_train,Y_train):\n",
    "    ind= range(len(Y_train))\n",
    "    d={\"x1\":pd.Series(X_train[:,0], index=ind),\"x2\":pd.Series(X_train[:,1], index=ind), \\\n",
    "       \"x3\":pd.Series(X_train[:,2], index=ind),\"x4\":pd.Series(X_train[:,3], index=ind),\"Label\":pd.Series(Y_train)}\n",
    "    df = pd.DataFrame(d)\n",
    "    sf=pd.DataFrame(columns=('x1', 'x2', 'x3','x4'))\n",
    "    vf=pd.DataFrame(columns=('x1', 'x2', 'x3','x4'))\n",
    "    for i in range(len(Y_train)):\n",
    "        if(df.Label[i] == 1):\n",
    "              sf.loc[i]=[df.x1[i],df.x2[i],df.x3[i],df.x4[i]]\n",
    "        else:\n",
    "              vf.loc[i]=[df.x1[i],df.x2[i],df.x3[i],df.x4[i]]\n",
    "    prior_setosa= float(len(sf))/float(len(df))\n",
    "    prior_versi=float(len(vf))/float(len(df))\n",
    "    cov_setosa=np.cov(sf.transpose())\n",
    "    cov_versi=np.cov(vf.transpose())\n",
    "    mean_setosa=[np.mean(sf.x1),np.mean(sf.x2),np.mean(sf.x3),np.mean(sf.x4)]\n",
    "    mean_versi=[np.mean(vf.x1),np.mean(vf.x2),np.mean(vf.x3),np.mean(vf.x4)]\n",
    "    return mean_setosa, mean_versi, cov_setosa, cov_versi, prior_setosa, prior_versi\n",
    "    \n",
    "\n",
    "def member(mean_setosa, mean_versi, cov_setosa, cov_versi,prior_setosa, prior_versi,X,Y):\n",
    "    g1=[]\n",
    "    g2=[]\n",
    "    d=pd.DataFrame(columns=('d', 'Label'))\n",
    "    for i in range(len(X)):\n",
    "        g1x= -m.log(np.linalg.det(cov_setosa)) - (0.5 *(np.dot((X[i]-mean_setosa).transpose(),np.dot(np.linalg.inv(cov_setosa),\\\n",
    "                                                      (X[i]-mean_setosa))))) + m.log(prior_setosa)\n",
    "        g1.append(g1x)\n",
    "        g2x= -m.log(np.linalg.det(cov_versi)) - (0.5 *(np.dot((X[i]-mean_versi).transpose(),np.dot(np.linalg.inv(cov_versi),\\\n",
    "                                                      (X[i]-mean_versi))))) + m.log(prior_versi)\n",
    "        g2.append(g2x)\n",
    "#         discriminant= g1[i]-g2[i]\n",
    "#         d.append(discriminant)\n",
    "        d.loc[i]=[g1[i]-g2[i], Y[i]]\n",
    "#     print d\n",
    "    return d\n",
    "    \n",
    "def classify(d,Fun):\n",
    "    c1=pd.DataFrame(columns=('c1','ALabel', 'PLabel','FunLabel'))\n",
    "    c2=pd.DataFrame(columns=('c2', 'ALabel','PLabel','FunLabel'))\n",
    "    for i in range(len(d)):\n",
    "        if(d.d[i]>=0):\n",
    "            c1.loc[i]=[d.d[i],d.Label[i],1,Fun[i]]\n",
    "        else:\n",
    "            c2.loc[i]=[d.d[i],d.Label[i],2,Fun[i]]\n",
    "#     print c1\n",
    "#     print c2\n",
    "    c=pd.concat([c1,c2])\n",
    "    return c\n",
    "  \n",
    "def confusion_mat(c):\n",
    "    mse=mean_squared_error(c.ALabel, c.PLabel)\n",
    "    print mse\n",
    "    TP=0\n",
    "    FP=0\n",
    "    TN=0\n",
    "    FN=0\n",
    "    for i in range(len(c)):\n",
    "        if (c.ALabel[i]== c.PLabel[i] and c.ALabel[i]==1):\n",
    "            TP+=1\n",
    "        if (c.ALabel[i]== c.PLabel[i] and c.ALabel[i]==2):\n",
    "            TN+=1\n",
    "        if(c.ALabel[i]==2 and c.PLabel[i]==1):\n",
    "            FP+=1\n",
    "        if(c.ALabel[i]==1 and c.PLabel[i]==2):\n",
    "            FN+=1\n",
    "    con_mat=np.matrix([[TP,FP],[FN,TN]])\n",
    "    Accuracy=float((TP+TN))/float((TP+FP+TN+FN))\n",
    "    print \"Accuracy: \",Accuracy\n",
    "    return con_mat\n",
    "    \n",
    "    \n",
    "def k_fold(X, Y, k_fold):\n",
    "    kf=sklearn.cross_validation.KFold(n=len(X), n_folds=10, shuffle=False,random_state=None)\n",
    "    for train_index, test_index in kf:\n",
    "        X_train,X_test=X[train_index], X[test_index]\n",
    "        Y_train,Y_test=Y[train_index], Y[test_index]\n",
    "        mean_setosa, mean_versi, cov_setosa, cov_versi,prior_setosa, prior_versi=calculate_mean_variance(X_train,Y_train)\n",
    "        d=member(mean_setosa, mean_versi, cov_setosa, cov_versi,prior_setosa, prior_versi,X_train, Y_train)\n",
    "        lda = LinearDiscriminantAnalysis()\n",
    "        clf = lda.fit(X_train,Y_train)\n",
    "        Fun1=clf.predict(X_train)\n",
    "        c=classify(d,Fun1)\n",
    "        con_mat=confusion_mat(c)\n",
    "        p1= (float(con_mat[0,0])/float((con_mat[0,0]+con_mat[0,1])))\n",
    "        r1=(float(con_mat[0,0])/float((con_mat[0,0]+con_mat[1,0])))\n",
    "        p2= (float(con_mat[1,1])/float((con_mat[1,1]+con_mat[1,0])))\n",
    "        r2=(float(con_mat[1,1])/float(con_mat[1,1]+con_mat[0,1]))\n",
    "        precision=[p1,p2]\n",
    "        recall=[r1,r2]\n",
    "        print \"Confusion Matrix: \",con_mat\n",
    "        print \"Precision: \",precision\n",
    "        print \"Recall: \" ,recall\n",
    "        F1=2*((p1*r1)/(p1+r1))\n",
    "        F2=2*((p2*r2)/(p2+r2))\n",
    "        print \"F_measure: \",[F1,F2]\n",
    "#         print X_train\n",
    "\n",
    "def main():\n",
    "    iris = load_iris()\n",
    "    X = iris.data \n",
    "    Y = iris.target\n",
    "    enc = LabelEncoder()\n",
    "    label_encoder = enc.fit(Y)\n",
    "    y = label_encoder.transform(Y) + 1\n",
    "    x=X[0:100]\n",
    "    y=y[0:100]\n",
    "#     without fold\n",
    "    print(\"Performance with 75% training size\")\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=42)\n",
    "    mean_setosa, mean_versi, cov_setosa, cov_versi,prior_setosa, prior_versi=calculate_mean_variance(X_train,y_train)\n",
    "    d=member(mean_setosa, mean_versi, cov_setosa, cov_versi,prior_setosa, prior_versi,X_test, y_test)\n",
    "    lda = LinearDiscriminantAnalysis()\n",
    "    clf = lda.fit(X_train,y_train)\n",
    "    Fun=clf.predict(X_test)\n",
    "    c=classify(d,Fun)\n",
    "    con_mat=confusion_mat(c)\n",
    "    p1= (float(con_mat[0,0])/float((con_mat[0,0]+con_mat[0,1])))\n",
    "    r1=(float(con_mat[0,0])/float((con_mat[0,0]+con_mat[1,0])))\n",
    "    p2= (float(con_mat[1,1])/float((con_mat[1,1]+con_mat[1,0])))\n",
    "    r2=(float(con_mat[1,1])/float(con_mat[1,1]+con_mat[0,1]))\n",
    "    precision=[p1,p2]\n",
    "    recall=[r1,r2]\n",
    "    print \"Confusion Matrix: \",con_mat\n",
    "    print \"Precision: \",precision\n",
    "    print \"Recall: \" ,recall\n",
    "    F1=2*((p1*r1)/(p1+r1))\n",
    "    F2=2*((p2*r2)/(p2+r2))\n",
    "    print \"F_measure: \",[F1,F2]\n",
    "    p=dict()\n",
    "    r=dict()\n",
    "    av_p=dict()\n",
    "    for i in range(2):\n",
    "        p[i], r[i], _ = precision_recall_curve(c.ALabel,\n",
    "                                                c.PLabel,pos_label=1)\n",
    "#         av_p[i] = average_precision_score(c.ALabel, c.PLabel)\n",
    "\n",
    "    for i in range(2):\n",
    "        plt.plot(r[i], p[i])\n",
    "#     for i in range(2):\n",
    "#         plt.plot(precision[i],recall[i])\n",
    "    plt.xlim([0.0, 1.5])\n",
    "    plt.ylim([0.0, 1.5])\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title('Precision-Recall curve')\n",
    "    plt.show()\n",
    "\n",
    "#     With fold\n",
    "    print(\"******\")\n",
    "    print(\"Performance with 10 fold\")\n",
    "    k_fold(x,y,10)\n",
    "    \n",
    "    \n",
    "    \n",
    "if __name__ == \"__main__\":main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
